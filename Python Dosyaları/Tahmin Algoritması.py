# -*- coding: utf-8 -*-
"""Duygu Analizi

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WyG60MffFzSzvPM_mE_5XkbJAnuVtPKv
"""

import numpy as np
import pandas as pd

from collections import Counter
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.stem.porter import PorterStemmer
import nltk as nlp
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import re


from sklearn.model_selection import train_test_split

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

test_data = pd.read_csv("/content/test_2.csv")
train_data = pd.read_csv("/content/train_2.csv")
valid_data = pd.read_csv("/content/valid_2.csv")

data = pd.concat([test_data,train_data,valid_data] , axis = 0)

data.drop("Unnamed: 0" ,axis = 1, inplace = True)

data.dropna(inplace = True)

tfidf=TfidfVectorizer(min_df=7, 
                      max_df=0.8,
                      strip_accents=None,
                      lowercase=False,
                      preprocessor=None,
                      use_idf=True,
                      norm='l2',
                      smooth_idf=True)

y=data.label.values
x_fit=tfidf.fit(data.text)
x = x_fit.transform(data.text)

X_train,X_test,y_train,y_test=train_test_split(x,y,
                                               random_state=1,
                                               test_size=0.5,
                                               shuffle=False)

from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
svm = SVC(random_state = 42)
svm.fit(X_train,y_train)
print("Support Vector Machine Test Accuracy {}".format(svm.score(X_test , y_test)))

metin = input("Duygu Analizini Yapmak İstediğiniz İngilizce Cümleyi Yazınız ")

metin = re.sub("[^a-zA-Z]" ," ",metin)
metin = metin.lower()
metin = nlp.word_tokenize(metin)
metin = [word for word in metin if not word in set(stopwords.words("english"))]
lemma = nlp.WordNetLemmatizer()
metin = [lemma.lemmatize(word) for word in metin]
metin = " ".join(metin)
#vektörizasyon
metin_vektörü = x_fit.transform([metin])
#algoritma
sonuc = svm.predict(metin_vektörü)

if sonuc == 1:
  print("Bu cümle olumlu bir cümledir")
else:
    print("Bu cümle olumsuz bir cümledir")

